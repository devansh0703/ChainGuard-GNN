Towards Quantum-Ready Blockchain Fraud
Detection via Ensemble Graph Neural Networks
M.Z. Haider1 , Tayyaba Noreen1 , M. Salman2
1 Department of Software Engineering(ÉTS), Université du Québec, Canada

arXiv:2509.23101v1 [cs.LG] 27 Sep 2025

2 Department of Computer Science, SZABIST University

Abstract—Blockchain Business applications and cryptocurrencies such as enable secure, decentralized value transfer,
yet their pseudonymous nature creates opportunities for illicit
activity, challenging regulators and exchanges in anti-money
laundering (AML) enforcement. Detecting fraudulent transactions in blockchain networks requires models that can capture
both structural and temporal dependencies while remaining
resilient to noise, imbalance, and adversarial behavior. In this
work, we propose an ensemble framework that integrates Graph
Convolutional Networks (GCN), Graph Attention Networks
(GAT), and Graph Isomorphism Networks (GIN) to enhance
blockchain fraud detection. Using the real-world Elliptic dataset,
our tuned soft voting ensemble achieves high recall of illicit
transactions while maintaining a false positive rate below 1%,
beating individual GNN models and baseline methods. The modular architecture incorporates quantum-ready design hooks, allowing seamless future integration of quantum feature mappings
and hybrid quantum–classical graph neural networks. This
ensures scalability, robustness, and long-term adaptability as
quantum computing technologies mature. Our findings highlight
ensemble GNNs as a practical and forward-looking solution for
real-time cryptocurrency monitoring, providing both immediate
AML utility and a pathway toward quantum-enhanced financial
security analytics.
Index Terms—Blockchain Fraud Detection, Graph Neural
Networks, Ensemble Learning, Quantum Machine Learning,
Quantum-Ready Systems

I. I NTRODUCTION
Blockchain has transformed digital finance by enabling
secure, decentralized, and transparent transactions, with Bitcoin showcasing its global potential. Yet, the pseudonymous
nature of cryptocurrency also facilitates illicit activities such
as money laundering and ransomware, creating challenges for
AML enforcement [1]. Detecting fraud is difficult due to the
scale and complexity of blockchain transaction graphs, where
conventional machine learning often falls short. Graph Neural
Networks (GNNs) address this gap by capturing relational and
structural patterns [2], [3]. While GCNs, GATs, and GINs
each offer unique strengths, single models remain sensitive
to noise and sparsity[4]. To overcome this, we propose an
ensemble framework integrating these architectures via equalweight, tuned-weight, and stacking strategies. The tuned softvoting ensemble achieves the best results, detecting over 70%
of illicit transactions in the Elliptic dataset with under 1%
false positives, demonstrating practical value for real-time
AML[1], [5].

Graph Neural Networks (GNNs) have advanced blockchain
analytics beyond shallow embeddings and hand-crafted features by combining node attributes with multi-hop structural
dependencies. Weber et al. [1] demonstrated the effectiveness
of GCNs on the Bitcoin Elliptic dataset for AML tasks,
while Wang et al. [3] showed that incorporating topological
and temporal features further improves illicit transaction
detection in large-scale networks. Similarly, Gai et al. [2]
proposed a privacy-preserving federated GNN framework
for financial data, supporting collaborative model training
without exposing sensitive information[6]. Beyond classical GNNs such as GCN, GAT, and GIN, ensemble strategies enhance robustness by leveraging their complementary
strengths, as shown in recent multi-model voting and stacking
approaches [7]. In parallel, quantum readiness has gained attention with advances in Quantum Machine Learning (QML)
and Quantum GNNs (QGNNs). Hybrid quantum–classical
models [8], surveys on QML for graphs [5], and designs
like VQGNN [9] highlight their potential for scalable graph
analytics. In blockchain contexts, researchers have proposed
quantum-enhanced and quantum-resistant frameworks for secure decentralized ledgers [10], [11].
These developments suggest that future blockchain fraud
detection will combine ensemble GNNs with quantumenhanced modules. Our modular framework is designed with
a quantum-ready perspective, enabling seamless integration of
QGNNs as they mature. Advances in QML and QGNNs [8],
[5], [9] promise improved scalability through quantum parallelism, while quantum-enhanced and quantum-resistant mechanisms [10], [11] can further strengthen blockchain security
and analytics. The contributions of our work are as follows:
1) Ensemble GNN Framework: A robust blockchain
fraud detection system combining GCN, GAT, and
GIN models to leverage complementary graph learning
capabilities.
2) Comprehensive Evaluation: Performance assessment
on the real-world Elliptic dataset, showing strong recall
and low false positive rates suitable for operational
AML contexts.
3) Quantum-Ready Architecture: A modular system
prepared for integration with future QGNN and hybrid
quantum–classical approaches to enhance scalability
and predictive performance.

The remaining sections are organized as follows. Section II
presents the background and related work. Section III introduces our proposed protocol, followed by Section IV, which
describes the methodology. Section V reports the evaluation
results, and Section VI concludes the paper.
II. BACKGROUND AND R ELATED W ORK
Before the advent of graph neural networks, blockchain
fraud detection relied heavily on conventional machine learning methods such as logistic regression, random forests,
and support vector machines[12]. These approaches typically
utilized handcrafted statistical features derived from transaction histories or aggregated account-level attributes. While
effective in capturing local heuristics, they often failed to generalize across dynamic and large-scale blockchain transaction
graphs. For instance, Fan et al. [13] highlighted the limitations
of traditional ML in addressing structural dependencies, emphasizing the need for graph-based models. Similarly, Hu et
al. [14] demonstrated that feature-engineering-based anomaly
detection suffers from high false-positive rates when applied
to evolving blockchain data. Graph Neural Networks (GNNs)
have emerged as state-of-the-art techniques for blockchain
analytics by directly modeling the relational dependencies
between entities[15]. Recent works demonstrated their superiority in capturing complex illicit behavior patterns[16].
Wang et al. [3] integrated topological and temporal features
into a temporal GNN framework for transaction monitoring, showing improved precision over flat ML models. Liu
et al. [17] designed a heterogeneous GNN for financial
transaction networks, enabling fine-grained fraud detection
by combining node-level and edge-level embeddings. More
recently, Lin et al. [18] introduced BlockGNN, a scalable
framework capable of detecting illicit Bitcoin transactions
under highly imbalanced class distributions. These advances
indicate that GNNs are well-suited to blockchain forensics
due to their ability to capture hierarchical and temporal graph
structures[19]. Ensemble learning enhances robustness by
aggregating multiple models, mitigating the noise and sparsity issues prevalent in blockchain networks. Recent studies
demonstrate the effectiveness of ensemble methods in financial anomaly detection. Abdullah et al. [7] combined multiple
GNN architectures through voting and stacking strategies,
achieving higher recall on blockchain transaction datasets. In
a related financial setting, Zhang et al. [20] applied ensemble
deep learning for credit fraud detection, highlighting its
ability to reduce false positives in highly imbalanced datasets.
Furthermore, Xu et al. [21] proposed a multi-model ensemble
framework that fuses temporal deep networks with GNNs,
achieving state-of-the-art accuracy in anti-money laundering
tasks. These findings suggest that ensemble learning is a
promising direction for improving blockchain fraud detection
systems[22]. The rapid advancement of quantum machine
learning (QML) motivates the integration of quantum models
with GNNs to achieve scalability and computational efficiency. Chen et al. [8] presented a hybrid quantum–classical

GNN that leverages quantum circuits for richer feature transformations, reporting promising results on node classification
tasks. Biamonte and Wang [5] surveyed QML for graphstructured data, identifying Quantum Graph Neural Networks
(QGNN) as a key frontier for high-dimensional graph learning. Mernyei et al. [9] introduced the Variational Quantum
Graph Neural Network (VQGNN), incorporating parameterized quantum circuits into message passing. In the blockchain
domain, Zhang et al. [10] explored quantum-enhanced and
quantum-resistant methods for secure decentralized ledgers,
while Salah et al. [11] reviewed applications of quantum
blockchain for secure data exchange. These developments
establish the foundation for quantum-ready architectures that
can seamlessly integrate quantum modules into classical fraud
detection pipelines.
III. P ROPOSED F RAMEWORK
A. System Overview
The framework provides a modular pipeline for blockchain
fraud detection using ensemble GNNs. Transaction data is
converted into attributed graphs, with nodes as transactions
and edges as value flows. The system proceeds in three
steps: (1) graph construction with attributes such as amounts,
timestamps, and metadata; (2) parallel use of GCN, GAT,
and GIN to capture local, attention-based, and structural
patterns; and (3) ensemble integration with tuned soft-voting
or stacking to reduce bias and enhance robustness.
B. Tuned Soft Voting and Stacking Strategy
To integrate base GNN predictions, the framework employs a two-layer ensemble combining tuned soft voting and
stacking. This hybrid design goes beyond naı̈ve averaging by
optimizing weights and modeling higher-order dependencies,
ensuring robustness against class imbalance, noisy labels, and
heterogeneous graph structures. In tuned soft voting, each
GNN outputs a probabilistic score, and weights are learned
from validation data to maximize recall on illicit transactions
while controlling false positives. This calibration emphasizes
model strengths, like GAT captures influence patterns while
GIN distinguishes subtle structures—yielding a risk-sensitive
aggregation that improves overall fraud detection. While
tuned soft voting offers an optimized linear blend of outputs,
it cannot capture complex interactions among models. To
address this, the framework adds a stacking layer, where a
meta-classifier is trained on the output probabilities of GCN,
GAT, and GIN. This allows the ensemble to learn nonlinear
dependencies, such as treating agreement between GAT and
GIN as a strong fraud signal, or down-weighting conflicting
predictions, thereby complementing soft voting with greater
adaptability and flexibility. Together, these mechanisms form
a synergistic ensemble. Tuned soft voting ensures stable,
interpretable predictions suitable for real-time monitoring,
while stacking adds flexibility by exploiting inter-model relationships and residual signals. This hybrid design balances

Fig. 1. Proposed blockchain fraud detection methodology pipeline.

robustness with sensitivity, enabling consistent performance
in deployment while remaining agile enough to capture subtle
fraudulent anomalies in blockchain networks.

Given a transaction vector x ∈ Rd representing attributes such
as amount, frequency, and neighborhood degree, the quantum
feature encoding Φ(x) is defined as:
⊗n

Φ(x) = Uϕ(x) |0⟩

C. Quantum-Ready Modular Design
A key feature of the system is its quantum-ready modular
design, enabling future transition from classical ensembles to
hybrid quantum–classical architectures. Unlike conventional
GNN ensembles, it embeds hooks for quantum randomness
and transformations, motivated by the stochastic and highdimensional nature of blockchain fraud detection. In particular, quantum random number generators (QRNGs) replace pseudo-random seeds for initialization and ensemble
sampling, providing unbiased randomness that strengthens
anomaly detection. Let W = {w1 , w2 , . . . , wk } denote the
ensemble weights assigned to each GNN in the tuned soft
voting mechanism. In a classical setup, these weights are initialized using a pseudo-random generator P RN G(·), which
is inherently deterministic and thus potentially predictable.
In contrast, QRNGs generate entropy from physical quantum
processes, modeled as:
wi ∼ Uq (0, 1),

(1)

where Uq represents a uniform distribution sourced from
a QRNG. This ensures that the initialization process is
information-theoretically unpredictable, mitigating risks of
adversarial biasing in ensemble construction. Beyond initialization, the architecture is designed to embed transaction vectors into quantum feature spaces via quantum feature maps.

,

(2)

where Uϕ(x) is a parameterized unitary transformation encoding x into an n-qubit state. Typical encodings include
angle encoding, where each feature dimension is mapped
to a rotation angle, and amplitude encoding, where normalized feature vectors define the probability amplitudes of the
quantum state. The encoded state then resides in a Hilbert
space H2n , providing an exponentially richer representation
space compared to the classical d-dimensional embedding.
The message passing between nodes in the GNN is also
extended to support variational quantum circuits (VQC). In
the classical formulation, a message update for a node v with
neighborhood N (v) is expressed as:


X
(t) 
h(t+1)
= σ
W (t) h(t)
,
(3)
v
u +b
u∈N (v)

where σ(·) is a non-linear activation. In the quantum-ready
extension, the weight matrix W (t) is replaced by a parameterized quantum operation U (θ(t) ), and the aggregation process
is mediated through quantum measurement statistics:
h(t+1)
= Ez∼M(U (θ(t) )Φ(h(t) )) [z],
v
u

(4)

where, M(·) denotes the measurement operator with outcomes z. Quantum embeddings introduce non-linear expressivity beyond classical kernels at modest cost: amplitude

heterogeneous feature representation, and strict temporal segmentation, all of which must be addressed for effective model
training. From a quantum-readiness standpoint, its sparsity,
high-dimensional feature vectors, and temporal partitioning
make it suitable for integration with quantum feature maps
and quantum graph kernels.
B. Feature Engineering and Graph Construction

Fig. 2. Architecture of the fair transaction ordering protocol: from mempool
collection to randomized ordering and on-chain verification.

encoding scales as O(d), angle encoding as O(log d), and
variational quantum circuits add only O(poly(n)) gates per
step. This modular design allows the framework to operate
classically today while remaining adaptable to future integration of QRNGs and quantum circuits, making it both practical
now and scalable for quantum-enhanced security.
IV. M ETHODOLOGY
The methodology follows a structured pipeline that converts raw blockchain data into a graph-compatible format
suitable for graph neural network training. The workflow
encompasses feature extraction, graph construction, imbalance handling, and preparation for PyTorch Geometric, while
embedding quantum-ready components to ensure future extensibility. Each stage is designed to preserve data integrity
and provide a foundation for both classical and quantumenhanced experimentation.
A. Dataset Description
The study is based on the Elliptic Bitcoin transaction
dataset, a curated subset of the Bitcoin ledger released
for anti-money laundering research. It spans 49 consecutive
two-week intervals between 2013 and 2017, encompassing
203,769 transactions connected by 234,355 directed payment
edges. Each transaction is represented as a node, and edges
capture the temporal flow of payments. A subset of nodes
is labeled as licit or illicit, with the remainder unlabeled, reflecting real-world uncertainty in blockchain monitoring. The
dataset poses three key challenges: extreme class imbalance,

Each transaction in the dataset is represented by a highdimensional feature vector that integrates both intrinsic transactional properties and aggregated neighborhood-level statistics. In total, we construct a 166-dimensional feature vector
xi ∈ R166 for every transaction node vi , which serves as
the primary input to the graph neural network. These features
are carefully engineered to balance discriminative power with
privacy preservation, ensuring that sensitive or personally
identifiable information is not exposed during training. The
first category of features captures the direct properties of
individual transactions. Each transaction Ti is represented as a
tuple (Vin , Vout , f, s), where Vin and Vout denote the number
of inputs and outputs, f is the transaction fee, and s is the
total size in bytes. To ensure comparability, these values are
normalized using z-score normalization:
xj − µ j
, ∀j ∈ {1, . . . , d},
(5)
x̂j =
σj
where µj and σj denote the mean and standard deviation
of feature j. Beyond these basic attributes, the dispersion of
funds across outputs provides additional insights. It is defined
as:
Vout
1 X
D(Ti ) =
(ok − ō)2 ,
(6)
Vout
k=1

where ok is the value of the k-th output and ō is the
mean output value. This metric highlights whether funds are
concentrated in a single output—a pattern often linked to
laundering or evenly distributed across recipients. The second
category aggregates statistics from the one-hop neighborhood
of each transaction in the graph. For a node vi with neighborhood N (vi ), features such as the average input value and the
variance of output distributions are computed. The average
input value is defined as:
X
1
InVal(u),
(7)
AvgIn(vi ) =
|N (vi )|
u∈N (vi )

while the variance of outputs is given by:
X
2
1
VarOut(vi ) =
OutVal(u) − OutVal . (8)
|N (vi )|
u∈N (vi )

Here, InVal(u) and OutVal(u) denote the total input and
output values of a neighboring transaction u, and OutVal
is their mean. These features capture local connectivity and
are particularly valuable in detecting collusive subgraphs or
chains of suspicious transfers. Transactions are modeled as a
temporal directed graph G = (V, E, X, T ), where V is the

set of transactions, E the edges, X ∈ R|V |×166 the feature
matrix, and T the discrete time steps. An edge (vi , vj ) ∈ E
exists if funds from Ti flow into Tj with ti < tj , ensuring
causal consistency. The adjacency matrix A ∈ {0, 1}|V |×|V |
is thus defined as
(
1 if Ti funds Tj , ti < tj ,
Aij =
(9)
0 otherwise.
The sequence {G(1) , G(2) , . . . , G(T ) } captures temporal propagation, where fraud often appears as bursts or layered flows.
Features are standardized and anonymized by removing IDs
and wallet addresses, preserving only statistical aggregates.
Node attributes (X) reveal transaction-level irregularities,
while the structure (A) propagates context, aiding in detecting
chain-hopping, circular flows, and mixing.
C. Data Cleaning and Integrity Checks
Ensuring the integrity and reliability of the transaction
dataset is essential, as noisy or inconsistent data can severely
degrade the performance of graph-based learning models. The
preprocessing pipeline therefore applies a multi-stage cleaning and verification procedure, yielding a graph object that
is both structurally valid and analytically consistent. The first
step addresses redundancy and consistency in node identifiers.
Since blockchain records can occasionally contain duplicate
entries, we remove duplicates by enforcing a uniqueness
constraint on transaction identifiers:
V ∗ = {vi ∈ V | ID(vi ) ∈
/ D},

(10)

where D denotes the set of already-seen identifiers. This
ensures that each node in the graph corresponds to a unique
transaction. Next, we validate graph connectivity by discarding edges pointing to missing or invalid nodes. Given an edge
set E, the cleaned set E ∗ is defined as:
E ∗ = {(u, v) ∈ E | u ∈ V ∗ , v ∈ V ∗ },

(11)

which guarantees that every edge connects two valid nodes
in the cleaned transaction set. This step prevents messagepassing layers from propagating undefined or incomplete feature information during training. To harmonize classification
targets, labels are normalized into a standardized three-class
scheme: licit, illicit, or unknown. This consolidation resolves
inconsistent annotations in the raw dataset and ensures the
classification task is well-posed, with all nodes mapped
into one of the three categories. The cleaned graph is then
remapped from hash-based identifiers to contiguous integer
indices, producing adjacency and feature matrices suitable
for frameworks such as PyTorch Geometric. Specifically,
the adjacency matrix A ∈ {0, 1}|V |×|V | and feature matrix X ∈ R|V |×d are generated, along with label vector
Y ∈ {0, 1, 2}|V | . This conversion enables efficient tensor
operations during training and inference. To accelerate experimentation and reduce memory overhead, a stratified sampling
procedure selects a subset of nodes while maintaining the

original class proportions. Given the label distribution P (y)
in the full dataset, the sampled dataset S preserves this
distribution:
PS (y) ≈ P (y),

|S| ≈ 0.05|V |.

(12)

This ensures that minority classes such as illicit transactions
remain adequately represented, avoiding sampling bias. An
additional source of robustness is introduced by leveraging quantum random number generators (QRNGs) for both
sampling and weight initialization. Unlike pseudo-random
number generators (PRNGs), QRNGs generate entropy from
inherently unpredictable quantum processes. Let Rq denote
the distribution induced by a QRNG; node sampling is then
performed as:
vi ∼ Rq (V, pi ),
(13)
where pi is the stratified probability of selecting node vi . A
major challenge in blockchain fraud detection is the extreme
class imbalance, with illicit nodes under 3% of the dataset.
Without correction, models bias toward the majority class and
overlook fraud. To address this, we use stratified partitioning,
weighted loss functions, and structural graph features, with
an 80/10/10 split that preserves class ratios.
D. Handling Class Imbalance
A key challenge in blockchain fraud detection is the
severe imbalance between licit and illicit transactions, with
illicit nodes comprising less than 3% of the dataset. Without
correction, models would favor the majority class and miss
critical fraud cases. To mitigate this, we apply stratified
partitioning, weighted loss functions, and structural graph
features, using an 80/10/10 train–validation–test split that
preserves class ratios. Formally, if P (y) denotes the empirical
class distribution in the dataset, then the stratified splits
{Strain , Sval , Stest } are constructed such that:
P (y | Strain ) ≈ P (y | Sval ) ≈ P (y | Stest ) ≈ P (y).

(14)

This prevents distributional shift across subsets and ensures
that performance metrics remain consistent and representative. During training, imbalance is further mitigated using a
class-weighted cross-entropy loss, which increases the penalty
for misclassifying minority nodes. Let C = {0, 1} denote licit
and illicit classes, and let wc denote the weight assigned to
class c. The weights are computed as inversely proportional
to class frequencies:
wc =

N
,
|C| · Nc

(15)

where N is the total number of labeled nodes and Nc is the
number of nodes in class c. The weighted cross-entropy loss
is then:
N
X
L=−
wyi log pθ (yi | xi ),
(16)
i=1

where pθ is the model’s predicted probability distribution.
This setup ensures that illicit nodes, though scarce, exert

greater influence on gradient updates, boosting recall without
inflating false positives. Unlike traditional methods, GNNs
retain unlabeled nodes, which participate in message passing
and provide valuable context. An unlabeled transaction between illicit nodes can reinforce their classification by propagating structural cues. This amplifies minority-class signals
without oversampling, as embeddings from both labeled and
unlabeled nodes contribute to learning. Unlike resampling
methods such as oversampling, undersampling, or SMOTE,
which may distort data, our graph-based approach exploits
relational dependencies, reflecting blockchain realities where
illicit activity is rare but structurally embedded. By combining
stratified partitioning, weighted loss, and structural message
passing, the framework addresses imbalance with high fraud
sensitivity and low false positives.

Fig. 3. Recall evaluation vs transactions reviewed.

E. Temporal Segmentation and Splitting Strategy
To evaluate robustness under realistic deployment conditions, the framework adopts two complementary evaluation
strategies: stratified random splits and chronological splits.
These strategies allow us to disentangle the effects of class
imbalance from temporal dynamics, thereby providing a
comprehensive assessment of generalization. In the stratified
random split, all labeled nodes are partitioned into training,
validation, and test sets (80/10/10) while preserving global
class proportions. Formally, if P (y) denotes the empirical
label distribution in the dataset, the splits {Strain , Sval , Stest }
are constructed such that:
P (y | Strain ) ≈ P (y | Sval ) ≈ P (y | Stest ) ≈ P (y).

(17)

This ensures that rare illicit transactions remain adequately
represented across splits, reducing sampling bias and enabling
reliable evaluation of precision–recall trade-offs.
In contrast, the chronological split reflects deployment
realities, where models must generalize from historical data to
unseen future activity. The dataset is divided into training, validation, and test segments based on temporal order, with early
time steps used for training, intermediate steps for validation,
and later steps reserved for testing. This enforces temporal
causality by ensuring that training always precedes validation
and testing, thereby avoiding data leakage and providing
a faithful measure of temporal generalization. Performance
differences between stratified and chronological evaluations
indicate how much the model depends on structural correlations versus temporal stability.
Exploratory analysis of each temporal segment highlights
structural patterns of the transaction network. Degree distributions follow a heavy-tailed power law,
P (d) ∝ d−γ ,

γ ∈ [2, 3],

(18)

with short path lengths and multiple weakly connected components, reflecting small-world effects and heterogeneous user
communities. These properties guide GNN design, weighted
aggregation to counter hub dominance, and also suggest

Fig. 4. Performance comparison on stratified random vs chronological splits.

quantum-ready extensions. Centrality and clustering measures
can be reformulated via amplitude encoding, while temporal
dependencies may be modeled through parameterized quantum circuits, positioning the framework for seamless hybrid
quantum–classical integration.
V. E XPERIMENTAL E VALUATION
A. Evaluation Metrics
Because illicit nodes account for less than three percent
of the dataset, overall accuracy is misleading; a trivial model
that labels all transactions as licit would exceed 97% accuracy
while failing to detect fraud. To address this imbalance,
our evaluation focuses on precision, recall, F1-score, false
positive rate (FPR), and threshold-independent metrics such
as the area under the precision–recall curve (PR-AUC) and
the area under the receiver operating characteristic curve
(ROC-AUC). Precision reflects the reliability of fraud alerts,
while recall captures the system’s sensitivity to true illicit
cases. Their balance is summarized by the F1-score, which
is critical in fraud detection tasks. The false positive rate is
also reported, as even small increases in false alarms can
overwhelm compliance teams. Finally, PR-AUC is particularly informative for imbalanced data, whereas ROC-AUC
provides a broader view of classification performance. As
illustrated in Figure 3, the ensemble achieves high recall on
illicit transactions with minimal false positives, demonstrating
effectiveness for practical anti-money laundering applications.

Fig. 5. Comparative analysis of GCN, GAT, GIN, and ensemble strategies. (a) Precision–recall trade-offs visualized with dumbbell plots, showing performance
gaps (∆) between precision and recall. (b) Model ranking by illicit-class F1-score using lollipop plots, where tuned soft-voting and stacking ensembles achieve
the highest scores.

B. Results on Random and Chronological Splits
To assess the robustness of the proposed framework, we
evaluate performance under two complementary data partitioning strategies: stratified random splits and chronological
splits. The stratified random split serves as an upper-bound
benchmark by distributing labeled nodes into training, validation, and test sets while preserving the global class ratio. In
contrast, the chronological split enforces temporal causality
by training on early time steps, validating on intermediate
ones, and testing on later periods, thereby simulating realworld deployment where illicit activity evolves. If P (y)
denotes the empirical class distribution, the stratified split
ensures
P (y | Strain ) ≈ P (y | Sval ) ≈ P (y | Stest ),

(19)

preserving class proportions across subsets. For chronological
splits, the dataset {G(1) , . . . , G(T ) } is partitioned as:
Strain = {G(1) , . . . , G(αT ) },
Sval = {G(αT +1) , . . . , G(βT ) },
Stest = {G(βT +1) , . . . , G(T ) }.

(20)

with 0 < α < β < 1. This guarantees ttrain < tval < ttest
and prevents information leakage across time. Empirical results confirm that the ensemble achieves consistently strong
performance in both settings. Under the stratified split, the
ensemble attains an illicit recall above 70% with a false
positive rate under 1%, representing a best-case performance
scenario. Under chronological splits, recall remains high but
decreases slightly, reflecting the natural challenge of generalizing to previously unseen fraud patterns. This performance gap highlights the importance of temporal robustness
in blockchain monitoring systems: models must adapt to
evolving laundering strategies rather than relying solely on
static correlations.
Figure 4 compares F1 and recall scores across the two
evaluation strategies. These findings suggest that the framework is suitable for the detection of blockchain fraud in the

real world, where future illicit behaviors may only partially
resemble those seen during training.
C. Comparative Analysis of GCN, GAT, GIN vs. Ensemble
We compared GCN, GAT, GIN, and three ensemble strategies: equal weight soft voting, tuned soft voting, and stacking,
focusing on illicit class performance, which is critical for
AML. Figure 5(a) illustrates the precision–recall trade-offs.
GCN shows high precision (0.86) but low recall (0.47), while
GAT performs worst (R = 0.19). GIN achieves the best
single-model balance (P = 0.83, R = 0.74). Ensemble
methods consistently narrow this gap, with tuned soft voting
delivering the best compromise (P = 0.87, R = 0.72),
confirming the robustness of weighted fusion under class
imbalance.
Figure 5(b) shows a lollipop ranking of illicit-class F1scores. The visualization highlights the relative ordering of
models: GAT is the weakest (F 1 = 0.30), GCN improves
moderately (F 1 = 0.61), while GIN provides a strong
backbone (F 1 = 0.78). Both the tuned ensemble and stacking
achieve comparable top-ranked performance (F 1 ≈ 0.78),
marginally surpassing GIN by combining multiple decision
boundaries. This illustrates the value of ensembles not only
in improving recall but also in stabilizing predictions across
heterogeneous graph structures. In general, the comparative
analysis shows that while individual GNNs capture the distinct structural properties of the blockchain transaction graph,
the ensemble methods, particularly the tuned soft voting, provide superior and more balanced fraud detection performance.
These results underscore the practical importance of ensemble
GNN architectures in safeguarding blockchain ecosystems
against illicit financial activity.
D. Comparative Evaluation with Existing Frameworks
We compared the ensemble GNN with baselines including
Random Forest, Tx2Vec+XGBoost, Core-set, LLAL, and
Entropy-based selection. Figure 6 reports PR-AUC as labeled

Fig. 6. Fraud detection performance PR-AUC

data grows from 1k to 10k. The ensemble consistently outperforms all baselines: while Tx2Vec+XGBoost and LLAL
remain competitive, they plateau at lower values, and random selection performs worst. At 10k labels, the ensemble
reaches 75.0% PR-AUC, surpassing Core-set (72.8%), LLAL
(74.4%), Entropy (72.3%), and Random (71.2%). These gains
highlight the robustness of integrating GCN, GAT, and GIN
with tuned soft voting, yielding balanced recall and precision
under class imbalance and setting a new benchmark for
blockchain fraud detection.
VI. C ONCLUSION
This paper presented an ensemble-based graph neural network framework for blockchain fraud detection, addressing
the limitations of individual backbone models in highly imbalanced transaction datasets. Through a systematic evaluation
of GCN, GAT, and GIN architectures, we demonstrated
that while single GNNs capture complementary structural
properties of blockchain transaction networks, they exhibit
notable trade-offs between precision and recall. In particular, GCN achieved strong precision but suffered from low
recall, GAT underperformed on illicit detection, and GIN
achieved balanced performance with comparatively higher
recall. By integrating these models through ensemble strategies, especially tuned soft-voting and stacking, we achieved
consistently higher illicit-class recall and F1-scores without
sacrificing precision. The comparative analysis confirmed
that ensembles provide robustness against the weaknesses
of individual models, enabling more reliable detection of
fraudulent behavior. Moreover, our ablation and temporal
analyses highlighted the ensembles’ resilience to concept drift
across time steps, a critical requirement for deployment in
dynamic blockchain ecosystems.
R EFERENCES
[1] M. Weber, G. Domeniconi, J. Chen, D. K. Weidele, C. Bellei,
T. Robinson, and C. E. Leiserson, “Anti-money laundering in
bitcoin,” in Proceedings of the ACM, 2021. [Online]. Available:
https://doi.org/10.1145/3490354.3494360

[2] K. Gai, J. Guo, M. Qiu, and X. Sun, “Blockchain-assisted
privacy-preserving federated learning for financial big data,” IEEE
Transactions on Network Science and Engineering, 2022. [Online].
Available: https://doi.org/10.1109/TNSE.2022.3143207
[3] Y. Wang, L. Chen, and Y. Li, “Graph neural networkbased fraud detection in blockchain transaction networks,” IEEE
Access, vol. 11, pp. 45 321–45 334, 2023. [Online]. Available:
https://doi.org/10.1109/ACCESS.2023.3261847
[4] U. Ullah and B. Garcia-Zapirain, “Quantum machine learning revolution in healthcare: a systematic review of emerging perspectives and
applications,” IEEE Access, vol. 12, pp. 11 423–11 450, 2024.
[5] J. Biamonte and Z. Wang, “Quantum machine learning on graphs:
Methods and applications,” ACM Computing Surveys, 2022. [Online].
Available: https://doi.org/10.1145/3517031
[6] M. Haider, T. Noreen, M. Salman, M. D. de Assuncao, and
K. Zhang, “V-zor: Enabling verifiable cross-blockchain,” arXiv preprint
arXiv:2509.10996, 2025.
[7] M. Abdullah, A. Nazir, M. U. Khan, and N. Javaid, “Blockchain transaction classification using machine learning and network embeddings,”
Applied Sciences, vol. 13.
[8] S. Chen, X. Weng, Y. Wu, and L. Wang, “Hybrid
quantum–classical graph neural networks for node classification,”
IEEE Transactions on Computers, 2023. [Online]. Available:
https://doi.org/10.1109/TC.2023.3234567
[9] P. Mernyei, D. Mezei, and L. Cincio, “Variational quantum graph
neural networks,” IEEE Transactions on Quantum Engineering, 2024.
[Online]. Available: https://doi.org/10.1109/TQE.2024.3352345
[10] R. Zhang, S. Li, and W. Xie, “Quantum-resistant and quantumenhanced solutions for blockchain security,” IEEE Transactions
on Emerging Topics in Computing, 2024. [Online]. Available:
https://doi.org/10.1109/TETC.2024.3342191
[11] K. Salah, M. H. Rehman, and A. Al-Fuqaha, “Quantum
blockchain for secure and efficient data sharing,” IEEE
Communications Surveys & Tutorials, 2022. [Online]. Available:
https://doi.org/10.1109/COMST.2022.3174825
[12] N. Innan, M. A.-Z. Khan, and M. Bennai, “Financial fraud detection: a
comparative study of quantum machine learning models,” International
Journal of Quantum Information, vol. 22, no. 02, p. 2350044, 2024.
[13] C. Fan, R. Zhong, and J. Zhang, “A survey on blockchain-based
financial applications and machine learning approaches,” IEEE Access,
vol. 9, pp. 124 107–124 121, 2021.
[14] B. Hu, T. Chen, and X. Li, “Blockchain data analytics: Challenges,
methods, and opportunities,” Elsevier Future Generation Computer
Systems, vol. 123, pp. 387–402, 2021.
[15] N. Innan, A. Marchisio, M. Bennai, and M. Shafique, “Qfnn-ffd:
Quantum federated neural network for financial fraud detection,” in
2025 IEEE International Conference on Quantum Software (QSW).
IEEE, 2025, pp. 41–47.
[16] M. Haider, M. D. de Assuncao, and K. Zhang, “A range-based sharding (rbs) protocol for scalable enterprise blockchain,” arXiv preprint
arXiv:2509.11006, 2025.
[17] Y. Liu, W. Xu, and P. Zhao, “Graph neural network-based fraud
detection in financial transaction networks,” IEEE Transactions on
Neural Networks and Learning Systems, vol. 33, no. 12, pp. 7468–
7480, 2022.
[18] Z. Lin, Y. Tang, and Y. Zhou, “Blockgnn: Scalable graph neural networks for illicit blockchain transaction detection,” Elsevier Information
Sciences, vol. 658, p. 119874, 2024.
[19] A. S. Naik, E. Yeniaras, G. Hellstern, G. Prasad, and S. K. L. P.
Vishwakarma, “From portfolio optimization to quantum blockchain
and security: A systematic review of quantum computing in finance,”
Financial Innovation, vol. 11, no. 1, pp. 1–67, 2025.
[20] L. Zhang, F. Wang, and Q. Liu, “Ensemble deep learning for credit
fraud detection,” Elsevier Expert Systems with Applications, vol. 165,
p. 113943, 2021.
[21] Z. Xu, L. Sun, and H. Zhou, “Multi-model ensemble framework for
anti-money laundering in cryptocurrency,” IEEE Access, vol. 10, pp.
85 834–85 845, 2022.
[22] D. R. Sahu, H. Tiwari, D. S. Tomar, and R. Pateriya, “Quantum-resistant
cryptography to prevent from phishing attack exploiting blockchain
wallet,” in Sustainable security practices using blockchain, quantum
and post-quantum technologies for real time applications. Springer,
2024, pp. 171–191.

